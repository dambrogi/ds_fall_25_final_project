---
title: "Title TBD"
author: "Drew Ambrogi and Ameenah Habib"
date: "December 20, 2025"
output-file: ambrogi_habib_ds_final.html
format:
  html:
    embed-resources: true
  pdf: default
execute:
  echo: true
  message: false                     
  warning: false                  
---

# Introduction

(Insert Intro)

- Explain ACS variable choices, reasoning


# Dependencies

The following packages are needed to execute the code in this document:

```{r}
library(tidyverse)
library(httr)
library(jsonlite)
library(janitor)
library(tidycensus)
library(purrr)
library(tigris)
library(sf)
library(rpart)
library(parsnip)
library(tidymodels)
library(rpart.plot)
library(vip)
```

Additionally, a Census API key and an [NREL API key](https://developer.nrel.gov/signup) are required for this project. Both must be stored in your `.Renv`, with the NREL key stored as `NREL_API_KEY='yourkey'`.

# Gathering and Cleaning the Data

## Data Sources

(Describe NREL dataset)
(Describe ACS)

## Pulling the NREL Charger Data

Because we are dealing with a large data set and several API calls, the following code is wrapped in if statements, such that API calls will only be made if the data is not already stored on locally. `refresh_data_chargers` and `refresh_data_acs` allow for a manual override. 

Data is stored in the subdirectory `/data`, which is created if it doesn't exist already.

```{r}
if (!dir.exists("data")) dir.create("data")

refresh_data_chargers <-FALSE # set to TRUE to re-pull charger data
refresh_data_acs <- FALSE # set to TRUE if to re-pull ACS data

```

The code block below loads the API key and constructs a GET call to collect data on all public AV chargers in the US. In addition to their locations, the query also selects several variables about the chargers, which we ultimately did not end up using in this analysis. 

After confirming a successful response, the incoming JSON is parsed and converted into a dataframe, chargers. The latitude and longitude of each charger are then used to create point geometries. The coordinate reference system is reprojected to EPSG:5070 to allow distance calculations in meters. Buffers are applied around each charger point to account for the fact that chargers can serve nearby census tracts even when they do not fall directly within tract boundaries. We use a 1-mile buffer to define access, consistent with [NEVI guidelines](https://www.ibtta.org/sites/default/files/documents/Advocacy/IBTTA-NEVI-Program-Guide-FINAL-2022-0328.pdf) that place corridor fast chargers within 1 mile of a highway. Anchoring the buffer to this standard avoids an arbitrary cutoff and makes the access measure easier to interpret.

The resulting dataframe is then sotred locally for future access. 


```{r}

if (file.exists("data/chargers_sf.rds") && 
    file.exists("data/chargers_buffers_1mi.rds") && 
    !refresh_data_chargers)
{
  chargers_sf <- read_rds("data/chargers_sf.rds")
  chargers_buffers_1mi <- read_rds("data/chargers_buffers_1mi.rds")
} else {
  
  #Read API Key from env file
  nrel_key <- Sys.getenv("NREL_API_KEY")
  
  # Build and Send Request
  base_url <- "https://developer.nrel.gov/api/alt-fuel-stations/v1.json"
  
  params <- list(
    api_key = nrel_key,
    fuel_type = "ELEC", # electric
    access = "public", # public access_code
    country = "US", # US stations
    status = "E", # only available stations
    limit  = "all" 
  )
  
  chargers_json <- GET(base_url, query = params)
  
  # Check the response
  http_status(chargers_json)
  
  #parse the response
  chargers_text_json <- content(chargers_json, as = "text")
  chargers_parsed_json <- fromJSON(chargers_text_json, flatten = TRUE)
  chargers <- as_tibble(chargers_parsed_json$fuel_stations)
  
  chargers <- chargers |>
    select(
      id,
      station_name,
      street_address,
      city, 
      state,
      zip,
      plus4,
      restricted_access,
      access_detail_code,
      owner_type_code,
      facility_type,
      ev_level1_evse_num,
      ev_level2_evse_num,
      ev_connector_types,
      ev_network,
      ev_renewable_source,
      funding_sources,
      geocode_status,
      latitude,
      longitude,
      open_date
    )
  
  # turn latitude and longitude into geometries
  chargers_sf <- chargers |>
    # drop rows with missing coords
    filter(!is.na(latitude), !is.na(longitude)) |>
    st_as_sf(
      coords = c("longitude", "latitude"),  
      crs    = 4326,                        
      remove = FALSE                       
    )
  
  chargers_sf <- st_transform(chargers_sf, 5070) #change to projected CRS in meters, for buffers
  
  chargers_buffers_1mi <- st_buffer(chargers_sf, dist = 1609.34) #creates one mile buffers
  
  #cache locally to avoid repeat pulls
  write_rds(chargers_sf, "data/chargers_sf.rds")
  write_rds(chargers_buffers_1mi, "data/chargers_buffers_1mi.rds")
}
```

## Pulling the ACS Data and Tract Geometries

We then construct a tract-level demographic dataset from the 2023 ACS 5-year survey to provide additional demographic information about each census tract. Again we check for a previous local version of the dataframe before rebuilding the data. We pull a set of pre-selected variables that we beleive will be both interesting and relevant to describing which tracts have charger access. 

(Finish this)

```{r}
if (file.exists("data/acs_clean_sf.rds") &&  !refresh_data_acs) {
  acs_clean_sf <- readr::read_rds("data/acs_clean_sf.rds")
} else {
  
  #constructing query and defining variables
  acs_year <- 2023
  acs_survey <- "acs5"
  
  acs_vars <- c(
    pop_total         = "B01003_001",  # Total pop
    
    white_nh          = "B03002_003",  # White alone, not Hispanic/Latino
    black_nh          = "B03002_004",  # Black alone, not Hispanic/Latino
    asian_nh          = "B03002_006",  # Asian alone, not Hispanic/Latino
    hispanic          = "B03002_012",  # Hispanic or Latino (any race)
    
    med_hh_income     = "B19013_001",  # Median hh income
    
    pov_total         = "B17001_001",  # Poverty universe
    pov_below         = "B17001_002",  # Below poverty
    
    lf_total          = "B23025_003",  # In labor force
    lf_unemployed     = "B23025_005",  # Unemployed
    
    occ_units_total   = "B25003_001",  # Occupied housing units
    occ_units_rent    = "B25003_003",  # Renter occupied
    
    units_total       = "B25024_001",  # Total housing units
    units_10_19       = "B25024_007",  # 10 to 19 units
    units_20_49       = "B25024_008",  # 20 to 49 units
    units_50_plus.    = "B25024_009",  # 50+ units
    
    hh_vehicles_total = "B08201_001",  # Households by vehicles available
    hh_zero_veh       = "B08201_002",  # No vehicle available
    
    commute_total     = "B08301_001",  # Workers by means of transportation to work
    commute_car_alone = "B08301_003",  # Car, truck, van, drove alone
    commute_carpool   = "B08301_004"   # Car, truck, van, carpooled
  )
  
  # helper function to pull state by state
  get_state_acs <- function(state_abbr) {
    get_acs(
      geography = "tract",
      state     = state_abbr,
      year      = acs_year,
      survey    = acs_survey,
      variables = acs_vars,
      geometry  = FALSE,   # will get from TIGRIS
      output    = "wide"   
    )
  }
  
  # get list of states, pull ACS for each with purr , dropping territories
  data("fips_codes")
  
  states_vec <- unique(fips_codes$state)
  states_vec <- states_vec[!states_vec %in% c("PR", "AS", "GU", "MP", "UM", "VI")]
  
  acs_tract_raw <- purrr::map_dfr(states_vec, get_state_acs)
  
  # cleaning the data
  acs_clean <- acs_tract_raw %>%
    transmute(
      GEOID,
      name = NAME,
      
      pop_total        = pop_totalE,
      
      white_nh         = white_nhE,
      black_nh         = black_nhE,
      asian_nh         = asian_nhE,
      hispanic         = hispanicE,
      
      med_hh_income    = med_hh_incomeE,
      
      pov_total        = pov_totalE,
      pov_below        = pov_belowE,
      
      lf_total         = lf_totalE,
      lf_unemployed    = lf_unemployedE,
      
      occ_units_total  = occ_units_totalE,
      occ_units_rent   = occ_units_rentE,
      
      units_total      = units_totalE,
      units_10_19      = units_10_19E,
      units_20_49      = units_20_49E,
      units_50_plus    = units_50_plusE,
      
      hh_vehicles_total = hh_vehicles_totalE,
      hh_zero_veh       = hh_zero_vehE,
      
      commute_total     = commute_totalE,
      commute_car_alone = commute_car_aloneE,
      commute_carpool   = commute_carpoolE
    ) %>%
    mutate(
      # race shares
      pct_white_nh  = white_nh  / pop_total,
      pct_black_nh  = black_nh  / pop_total,
      pct_asian_nh  = asian_nh  / pop_total,
      pct_hispanic  = hispanic  / pop_total,
      
      # poverty rate
      pov_rate      = if_else(pov_total > 0, pov_below / pov_total, NA_real_),
      
      # unemployment rate
      unemprate     = if_else(lf_total > 0, lf_unemployed / lf_total, NA_real_),
      
      # renter share
      renter_share  = if_else(occ_units_total > 0, occ_units_rent / occ_units_total, NA_real_),
      
      # large multifamily share (relative to occupied units)
      units_10plus = units_10_19 + units_20_49 + units_50_plus,
      multifam_share = if_else(units_total > 0, units_10plus / units_total, NA_real_),
      
      # zero vehicle households share
      zero_veh_share = if_else(hh_vehicles_total > 0, hh_zero_veh / hh_vehicles_total, NA_real_),
      
      # share commuting by car (alone plus carpool)
      commute_car_share = if_else(
        commute_total > 0,
        (commute_car_alone + commute_carpool) / commute_total,
        NA_real_
      )
    )
  
  # get geometries for tracts from TIGRIS
  get_state_tract_shapes <- function(state_abbr) {
    tracts(
      state = state_abbr,
      year  = acs_year,
      cb    = TRUE  
    )
  }
  
  tract_shapes <- purrr::map_dfr(states_vec, get_state_tract_shapes)
  
  # join geometries and demographic info 
  acs_clean_sf <- tract_shapes %>%
    left_join(acs_clean, by = "GEOID")
  
  write_rds(acs_clean_sf, "data/acs_clean_sf.rds")
}
```

## Merging and Preparing the Data Sets for Analysis

(Describe)

```{r}

acs_clean_sf_5070 <- st_transform(acs_clean_sf, st_crs(chargers_buffers_1mi)) #sets to same CRS

#joins charger buffers to tracts - tracts listed for each charger that intersects

tract_charger_pairs <- st_join(
  acs_clean_sf_5070,
  chargers_buffers_1mi %>%
    #preserve only select vars from chargers dataset
    select( 
      id,
      owner_type_code,
      facility_type,
      ev_level1_evse_num,
      ev_level2_evse_num,
      ev_connector_types,
      ev_network,
      ev_renewable_source,
      funding_sources
    ),  
  join = st_intersects,
  left = TRUE
)

#extract charger counts for each tract
tract_charger_counts <- tract_charger_pairs %>%
  st_drop_geometry() %>%       
  group_by(GEOID) %>%
  summarise(
    chargers_accessible = n_distinct(id, na.rm = TRUE),
    .groups = "drop"
  )

# join charger counts back to ACS data
#Add charger count variables, and pop_density, converting sq meters to square miles 
acs_with_access <- acs_clean_sf_5070 %>%
  left_join(tract_charger_counts, by = "GEOID") %>%
  mutate(
    chargers_accessible = replace_na(chargers_accessible, 0L),
    has_charger  = chargers_accessible > 0,
    land_sq_miles = ALAND / 2.58999e6,
    pop_density = if_else(land_sq_miles > 0, pop_total / land_sq_miles, NA_real_)
  )

# create charger density categories
acs_with_access <- acs_with_access %>%
  mutate(
    charger_cat = case_when(
      chargers_accessible == 0 ~ "None",
      chargers_accessible <= 2 ~ "Very low",
      chargers_accessible <= 7 ~ "Low–moderate",
      chargers_accessible <= 19 ~ "High",
      TRUE ~ "Very high"
    ),
    charger_cat = factor(
      charger_cat,
      levels = c("None", "Very low", "Low–moderate", "High", "Very high"),
      ordered = TRUE
    )
  )

write_rds(acs_clean_sf, "data/acs_with_access.rds")
```

# Exploratory Analysis

(Add)

(Explain distribution of chargers, decision to create categorical variable)

```{r}
summary(acs_with_access$chargers_accessible)
```

```{r}
acs_with_access %>%
  ggplot(aes(x = chargers_accessible)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "white") +
  labs(
    title = "Distribution of Accessible EV Chargers by Census Tract",
    x = "Number of Accessible Chargers",
    y = "Number of Census Tracts"
  ) +
  theme_minimal()
```
(Add plot of charger_cat)

# Exploring Predictors of Charger Access

(Explain choice of models)

## Linear Model 

We start with a simple OLS model. Here we opt for log chargers as our dependent variable, due to the long tail of in the distribution of charger counts. Because we are interested in the relative importance of our predictors, not their specific coefficients, we opt to normalise our variables for a cleaner comparison. 

### Defining and Fitting the Model

First we select a limited amount of variables as potential predictors, and eliminate other variables that may be duplicative or irrelevant. This collection of predictors is used across all three models. 

```{r}
predictors <- c(
  "pop_density",
  "med_hh_income",
  "pct_white_nh",
  "pct_black_nh",
  "pct_asian_nh",
  "pct_hispanic",
  "pov_rate",
  "unemprate",
  "renter_share",
  "multifam_share",
  "zero_veh_share",
  "commute_car_share"
)
```

Then we create a clean dataframe, dropping geometry, and logging the count of chargers. We then define and fit the model. 

```{r}
lm_df <- acs_with_access %>%
  sf::st_drop_geometry() %>%
  mutate(log_chargers = log1p(chargers_accessible)) %>%
  select(log_chargers, all_of(predictors)) %>%
  drop_na()

lm_rec_std <- recipe(log_chargers ~ ., data = lm_df) %>%
  step_normalize(all_predictors())

lm_spec <- linear_reg() %>%
  set_engine("lm")

lm_wf_std <- workflow() %>%
  add_recipe(lm_rec_std) %>%
  add_model(lm_spec)

lm_fit_std <- fit(lm_wf_std, data = lm_df)
```

### Evaluating the Model

Because we use the count of chargers as our dependent variable with this model, we can't evaluate accuracy, recall, and precision the way we do with our decision tree and LASSO models later. However, we can look at the model's R^2 to roughtly understand how much of the variation in charger counts our model accounts for. 

```{r}
glance(lm_fit_std) %>%
  select(r.squared, adj.r.squared, nobs)
```
We see that the model captured about 41% of the variation in charger counts. Substantial, but low enough to suggest there are other variables we aren't accounting for that play a significant role in determining counts. 

### Evaluating Variable Importance

To evaluate the importance of our predictors, we look at their coefficients. Since they have been normalized, we can easily compare them. 

```{r}
lm_coef_table_std <- tidy(lm_fit_std) %>%
  filter(term != "(Intercept)") %>%
  mutate(
    signif = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01 ~ "**",
      p.value < 0.05 ~ "*",
      p.value < 0.1 ~ "x",
      TRUE ~ ""
    ),
    estimate = round(estimate, 3),
    std.error = round(std.error, 3),
    p.value = round(p.value, 3)
  ) %>%
  arrange(desc(abs(estimate))) %>%
  select(term, estimate, std.error, p.value, signif)

lm_coef_table_std
```
With the exception of `pct_white_nh`, the percentage of the tract's population which is white (Non-Hispanic/Latino), all of our predictors are highly significant. 

A simple visualization makes the comparison more clear:
```{r}
plot_df_mag <- tidy(lm_fit_std) %>%
  filter(term != "(Intercept)") %>%
  mutate(
    mag = abs(estimate),
  ) %>%
  arrange(mag) %>%
  mutate(term = factor(term, levels = term))

lm_vi_plot <- ggplot(plot_df_mag, aes(x = mag, y = term)) +
  geom_col() +
  labs(
    x = "Absolute standardized coefficient",
    title = "Standardized OLS Model",
    subtitle = "Variable importance by magnitude"
  ) 

lm_vi_plot
```
(Importantly, this shows the absolute value of the magintude of each coefficient, though some variables had a negative impact on number of available chargers.)

The variable importance results suggest that charger deployment is being driven less by simple population metrics and more by housing type, travel behavior, and market conditions. The strongest positive predictors are renter share, median household income, and multifamily housing share. This pattern is intuitive. Renters and residents of multifamily buildings are less likely to have access to private, at home charging, which increases demand for public or shared chargers. At the same time, higher income areas are more likely to attract early infrastructure investment, either because residents are more likely to own EVs or because these neighborhoods have greater resources to support deployment.

Commute by car share plays a strongly negative role, which is consistent with the fact that our analysis focuses only on public chargers. In areas where a larger share of residents commute by car, households are more likely to have access to private parking and private chargers, reducing reliance on public infrastructure. Population density plays a smaller and negative role, suggesting that density alone does not guarantee more chargers. This makes sense, considering that in very dense urban neighborhoods, limited curb space, older infrastructure, and more complex permitting constraints can make deployment more difficult. This helps explain why both high commute by car share and high zero vehicle share are associated with fewer public chargers. On one end are tracts where private vehicles, parking, and home charging are common. On the other are dense urban tracts with fewer cars but greater physical and regulatory barriers. In both cases, demand for or feasibility of public chargers are lower.

The smaller effects for race, poverty, and related variables are harder to interpret directly and likely reflect broader neighborhood characteristics correlated with housing form, land use, and infrastructure conditions rather than intentional targeting. 

## Decision Tree Model

###Defining and Fitting the Model

We create a dataframe for use with this model, dropping grometries which are not needed for this analysis, and selecting the same set of predictors used in the previous model. We drop census tracks with NA values. We then split the data into testing and training sets.

```{r}
tree_model_df <- acs_with_access %>%
  st_drop_geometry() %>%
  select(charger_cat, all_of(predictors)) %>%
  na.omit()

# create a split object
tree_model_df_split <- initial_split(data = tree_model_df, prop = 0.75, strata = charger_cat)

# create the training and testing data sets
tree_model_df_train <- training(x = tree_model_df_split)
tree_model_df_test  <- testing(x = tree_model_df_split)
```

We fit a classification tree using rpart and set two regularization parameters to keep the model from chasing noise. The complexity parameter `(cp = 0.005)` so that a split is only kept if it improves model fit by at least about 0.5%, which discourages lots of small, low-value splits and produces a tree that is easier to interpret. We also set `minsplit = 250`, meaning a node must contain at least 250 training observations before it can be split.

```{r}
tree_rec <- recipe(charger_cat ~ ., data = tree_model_df_train)

tree_model <- decision_tree(mode = "classification") |>
  set_engine(
    "rpart",
    control = rpart.control(cp = 0.005, minsplit = 250)
  )

tree_wf <- workflow() |>
  add_recipe(tree_rec) |>
  add_model(tree_model)

# fit
rpart_fit <- tree_wf |>
  fit(data = tree_model_df_train)
```

### Evaluating the Model

We evaluate our model using the testing set, calculating precision, recall, and accuracy for both sets.

```{r}
train_preds <- predict(rpart_fit, tree_model_df_train, type = "class") |> 
  bind_cols(tree_model_df_train)

test_preds <- predict(rpart_fit, tree_model_df_test, type = "class") |> 
  bind_cols(tree_model_df_test)

tree_model_metrics <- tibble(
  train_precision = precision(data = train_preds, truth = charger_cat, estimate = .pred_class)$.estimate,
  train_recall = recall(data = train_preds, truth = charger_cat, estimate = .pred_class)$.estimate,
  train_accuracy = accuracy(data = train_preds, truth = charger_cat, estimate = .pred_class)$.estimate,
  test_precision = precision(data = test_preds, truth = charger_cat, estimate = .pred_class)$.estimate,
  test_recall = recall(data = test_preds, truth = charger_cat, estimate = .pred_class)$.estimate,
  test_accuracy = accuracy(data = test_preds, truth = charger_cat, estimate = .pred_class)$.estimate
)

tree_model_metrics
```
(Add evaluation)

### Evaluating Variable Importance

We examine variable importance from the fitted classification tree to understand which features the model relies on most when splitting observations.

```{r}
rpart_fit |>
  extract_fit_parsnip() |>
  vip()
```
(Add discussion about variable importance)

## LASSO Model

### Defining and Fitting the Model 

We use the same collection of predictors for our LASSO model, and split the data in the same way. We also confirm that our variable `charger_cat` is encoded as a factor. 

```{r}
lasso_df <- acs_with_access %>%
  st_drop_geometry() %>%
  select(charger_cat, all_of(predictors)) %>%
  na.omit() %>%
  mutate(charger_cat = factor(charger_cat))

set.seed(20201020)

# create a split object
lasso_df_split <- initial_split(data = lasso_df, prop = 0.75, strata = charger_cat)

# create the training and testing data
lasso_df_train <- training(x = lasso_df_split)
lasso_df_test  <- testing(x = lasso_df_split)
```

(Explain - cross validation, tuning grid, choice of metric)

```{r}
lasso_rec <- recipe(charger_cat ~ ., data = lasso_df_train) %>%
  step_normalize(all_numeric_predictors())

lasso_spec <- multinom_reg(penalty = tune(), mixture = 1)%>%
  set_engine("glmnet")

lasso_wf <- workflow() %>%
  add_recipe(lasso_rec) %>%
  add_model(lasso_spec)

folds <- vfold_cv(lasso_df_train, v = 5, strata = charger_cat)

lambda_grid <- grid_regular(penalty(), levels = 30)

lasso_tuned <- tune_grid(
  lasso_wf,
  resamples = folds,
  grid = lambda_grid,
  metrics = metric_set(accuracy, mn_log_loss)
)

best_lambda <- select_best(
  lasso_tuned,
  metric = "mn_log_loss"
)
```

(Explain why best lambda is basically 0)

```{r}
best_lambda

autoplot(lasso_tuned)
```
### Evaluating the Model

Using the same metrics as the decision tree

```{r}
final_lasso <- finalize_workflow(lasso_wf, best_lambda) %>%
  fit(data = lasso_df_train)

lasso_train_preds <- predict(final_lasso, lasso_df_train, type = "class") %>%
  bind_cols(lasso_df_train)

lasso_test_preds <- predict(final_lasso, lasso_df_test, type = "class") %>%
  bind_cols(lasso_df_test)

lasso_model_metrics <- tibble(
  train_precision = precision(lasso_train_preds, truth = charger_cat, estimate = .pred_class)$.estimate,
  train_recall    = recall(lasso_train_preds, truth = charger_cat, estimate = .pred_class)$.estimate,
  test_precision  = precision(lasso_test_preds, truth = charger_cat, estimate = .pred_class)$.estimate,
  test_recall     = recall(lasso_test_preds, truth = charger_cat, estimate = .pred_class)$.estimate,
  train_accuracy = accuracy(lasso_train_preds, truth = charger_cat, estimate = .pred_class)$.estimate,
  test_accuracy  = accuracy(lasso_test_preds, truth = charger_cat, estimate = .pred_class)$.estimate
)

lasso_model_metrics
```
### Evaluating Variable Importance

Top coefficients by class:

```{r}
coef_tbl <- final_lasso %>%
  extract_fit_parsnip() %>%
  tidy()

top_coef_by_class <- coef_tbl %>%
  filter(term != "(Intercept)") %>%
  group_by(class) %>%
  arrange(desc(abs(estimate)), .by_group = TRUE) 

top_coef_by_class
```

Survived variables by magnitude:

```{r}
survived_vars <- coef_tbl %>%
  filter(term != "(Intercept)") %>%
  group_by(term) %>%
  summarize(
    any_nonzero = any(estimate != 0),
    n_classes_nonzero = sum(estimate != 0),
    max_abs_coef = max(abs(estimate)),
    .groups = "drop"
  ) %>%
  filter(any_nonzero) %>%
  arrange(desc(max_abs_coef))

survived_vars %>%
  slice_head(n = 15) %>%
  ggplot(aes(x = reorder(term, max_abs_coef), y = max_abs_coef)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "LASSO survivors (non-zero coefficients)",
    x = NULL,
    y = "Max coefficient across classes"
  ) +
  theme_minimal()
```

## Discussion

# Conclusion



